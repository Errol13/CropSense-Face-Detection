import cv2
import os
import shutil
import numpy as np
from tqdm import tqdm

# Load the pre-trained s3fd face detection model
net = cv2.dnn.readNetFromCaffe("deploy.prototxt.txt", "res10_300x300_ssd_iter_140000.caffemodel")

# Set CUDA as the preferred backend and target
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)

# Create output folders for cropped images, debug images, and obstructed images
os.makedirs("output/upperbody_cropped", exist_ok=True)
os.makedirs("output/upperbody_debug", exist_ok=True)
os.makedirs("output/face_cropped", exist_ok=True)
os.makedirs("output/face_debug", exist_ok=True)
os.makedirs("output/obstructed_images", exist_ok=True)

# Get a list of input image paths
input_folder = "input"
output_upperbody_folder = "output/upperbody_cropped"
debug_upperbody_folder = "output/upperbody_debug"
output_face_folder = "output/face_cropped"
debug_face_folder = "output/face_debug"
obstructed_folder = "output/obstructed_images"
image_paths = [os.path.join(input_folder, file) for file in os.listdir(input_folder)]

# User input for selecting the option
option = int(input("Select an option:\n1. Upper Body\n2. Face\n"))

# Define margin values based on the selected option
if option == 1:
    left_margin_percent = 500
    top_margin_percent = 65
    right_margin_percent = 500
    bottom_margin_percent = 215
elif option == 2:
    left_margin_percent = 75
    top_margin_percent = 75
    right_margin_percent = 75
    bottom_margin_percent = 75
else:
    print("Invalid option selected. Exiting.")
    exit()

# Initialize progress bar
progress_bar = tqdm(total=len(image_paths), desc="Processing images")

# Process each image
for image_path in image_paths:
    # Load the image
    image = cv2.imread(image_path)
    
    # Perform face detection
    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
    net.setInput(blob)
    detections = net.forward()
    
    # Flag to check if the face is obstructed
    is_obstructed = False
    
    # Check if the face is obstructed
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        
        # Filter out weak detections
        if confidence > 0.5:
            box = detections[0, 0, i, 3:7] * np.array([image.shape[1], image.shape[0], image.shape[1], image.shape[0]])
            (startX, startY, endX, endY) = box.astype(int)
            
            # Calculate the width and height of the bounding box
            width = endX - startX
            height = endY - startY
            
            # Check if the width or height is too small
            if width < 64 or height < 64:
                is_obstructed = True
                break
    
    # Skip the image if the face is obstructed
    if is_obstructed:
        # Copy the original image to the obstructed images folder
        shutil.copy2(image_path, obstructed_folder)
        
        # Update progress bar
        progress_bar.update(1)
        continue
    
    # Crop and resize upper body or face for each detected face
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        
        # Filter out weak detections
        if confidence > 0.5:
            box = detections[0, 0, i, 3:7] * np.array([image.shape[1], image.shape[0], image.shape[1], image.shape[0]])
            (startX, startY, endX, endY) = box.astype(int)
            
            # Calculate the width and height of the bounding box
            width = endX - startX
            height = endY - startY
            
            # Calculate the margins for each side of the crop
            left_margin = width * left_margin_percent // 100
            top_margin = height * top_margin_percent // 100
            right_margin = width * right_margin_percent // 100
            bottom_margin = height * bottom_margin_percent // 100
            
            # Calculate the coordinates of the crop region
            crop_startX = max(startX - left_margin, 0)
            crop_startY = max(startY - top_margin, 0)
            crop_endX = min(endX + right_margin, image.shape[1])
            crop_endY = min(endY + bottom_margin, image.shape[0])
            
            # Crop the region
            cropped_region = image[crop_startY:crop_endY, crop_startX:crop_endX]

            # Check if the cropped region is valid (not empty)
            if cropped_region.size == 0:
                continue
            
            # Calculate the desired width and height for maintaining aspect ratio
            desired_width = 1080
            aspect_ratio = width / height
            desired_height = int(desired_width / aspect_ratio)

            # Resize the cropped region while maintaining aspect ratio
            resized_image = cv2.resize(cropped_region, (desired_width, desired_height))
            
            # Calculate the thickness of the rectangle based on the image resolution
            resolution_thickness_ratio = image.shape[1] // 1000
            thickness = max(resolution_thickness_ratio, 5)
            
            # Draw rectangle on debug image
            debug_image = image.copy()
            cv2.rectangle(debug_image, (crop_startX, crop_startY), (crop_endX, crop_endY), (0, 255, 0), thickness)

            # Add text label with original image resolution and confidence level
            resolution_text = f"{image.shape[1]}x{image.shape[0]} face_{i} ({int(confidence * 100)}%)"

            # Set the background color and text color
            background_color = (0, 0, 0)  # Black color for the background
            text_color = (255, 255, 255)  # White color for the text

            # Calculate the size of the text label
            text_size, _ = cv2.getTextSize(resolution_text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)

            # Create a rectangular background for the text
            background = np.zeros((text_size[1] + 10, text_size[0] + 10, 3), dtype=np.uint8)
            background[:, :] = background_color

            # Add the text label on top of the background
            text_position = (10, 30 + text_size[1])
            cv2.putText(background, resolution_text, (10, text_size[1] + 5), cv2.FONT_HERSHEY_SIMPLEX, 1, text_color, 2)

            # Combine the debug image and the background with text label
            debug_image[:text_size[1] + 10, :text_size[0] + 10] = background

            # Save the debug image with rectangle and label
            filename = os.path.splitext(os.path.basename(image_path))[0]
            debug_image_path = os.path.join(debug_upperbody_folder if option == 1 else debug_face_folder, f"{filename}_face_{i}.jpg")
            cv2.imwrite(debug_image_path, debug_image)
            
            # Save the cropped and resized image
            output_folder = output_upperbody_folder if option == 1 else output_face_folder
            output_image_path = os.path.join(output_folder, f"{filename}_face_{i}.jpg")
            cv2.imwrite(output_image_path, resized_image)
    
    # Update progress bar
    progress_bar.update(1)

# Close the progress bar
progress_bar.close()

# Calculate the total number of input images
total_images = len(image_paths)

# Calculate the number of successfully processed images
processed_images = total_images - len(os.listdir(obstructed_folder))

# Calculate the number of skipped images
skipped_images = len(os.listdir(obstructed_folder))

# Print the statistics
print(f"Total images: {total_images}")
print(f"Processed images: {processed_images}")
print(f"Skipped images: {skipped_images}")